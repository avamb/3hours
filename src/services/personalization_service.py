"""
MINDSETHAPPYBOT - Personalization service
Generates personalized responses using GPT-4 and user history
"""
import logging
from typing import List, Optional

from openai import AsyncOpenAI
from sqlalchemy import select

from src.config import get_settings
from src.db.database import get_session
from src.db.models import User, Moment
from src.utils.text_filters import ABROAD_PHRASE_RULE_RU, replace_abroad_phrases

logger = logging.getLogger(__name__)


class PersonalizationService:
    """Service for generating personalized responses"""

    def __init__(self):
        settings = get_settings()
        self.client = AsyncOpenAI(api_key=settings.openai_api_key)
        self.model = settings.openai_chat_model

    async def generate_response(
        self,
        telegram_id: int,
        moment_content: str,
    ) -> str:
        """
        Generate a personalized positive response to user's moment
        """
        try:
            # Get user for personalization
            async with get_session() as session:
                result = await session.execute(
                    select(User).where(User.telegram_id == telegram_id)
                )
                user = result.scalar_one_or_none()

            address = "–≤—ã" if (user and user.formal_address) else "—Ç—ã"

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": f"""–¢—ã ‚Äî —Ç—ë–ø–ª—ã–π –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π –±–æ—Ç –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è.
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–¥–µ–ª–∏–ª—Å—è —Ö–æ—Ä–æ—à–∏–º –º–æ–º–µ–Ω—Ç–æ–º –∏–∑ —Å–≤–æ–µ–π –∂–∏–∑–Ω–∏.
–û—Ç–≤–µ—Ç—å –∫–æ—Ä–æ—Ç–∫–æ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), —Ç–µ–ø–ª–æ –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–µ.
–ò—Å–ø–æ–ª—å–∑—É–π –æ–±—Ä–∞—â–µ–Ω–∏–µ –Ω–∞ ¬´{address}¬ª.
–ò—Å–ø–æ–ª—å–∑—É–π –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —ç–º–æ–¥–∑–∏ –¥–ª—è –ø–æ–∑–∏—Ç–∏–≤–∞.
–ù–µ –∑–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å–æ–≤, –ø—Ä–æ—Å—Ç–æ –ø–æ–¥–¥–µ—Ä–∂–∏.

{ABROAD_PHRASE_RULE_RU}""",
                    },
                    {
                        "role": "user",
                        "content": f"–ú–æ–π —Ö–æ—Ä–æ—à–∏–π –º–æ–º–µ–Ω—Ç: {moment_content}",
                    },
                ],
                max_tokens=150,
                temperature=0.7,
            )

            return replace_abroad_phrases(response.choices[0].message.content.strip())

        except Exception as e:
            logger.error(f"Failed to generate response: {e}")
            return "–°–ø–∞—Å–∏–±–æ, —á—Ç–æ –ø–æ–¥–µ–ª–∏–ª—Å—è! –≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∑–¥–æ—Ä–æ–≤–æ! üåü"

    async def detect_negative_mood(self, text: str) -> bool:
        """
        Detect if user's message indicates negative mood
        """
        negative_patterns = [
            "–Ω–∏—á–µ–≥–æ —Ö–æ—Ä–æ—à–µ–≥–æ",
            "–Ω–∏—á–µ–≥–æ –Ω–µ –ø—Ä–æ–∏–∑–æ—à–ª–æ",
            "–ø–ª–æ—Ö–æ",
            "–≥—Ä—É—Å—Ç–Ω–æ",
            "—Ç–æ—Å–∫–ª–∏–≤–æ",
            "—É–Ω—ã–ª–æ",
            "—É–∂–∞—Å–Ω–æ",
            "–Ω–µ –∑–Ω–∞—é",
            "–∑–∞—Ç—Ä—É–¥–Ω—è—é—Å—å",
        ]

        text_lower = text.lower()
        for pattern in negative_patterns:
            if pattern in text_lower:
                return True

        # Use GPT for more nuanced detection
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "–û–ø—Ä–µ–¥–µ–ª–∏, –≤—ã—Ä–∞–∂–∞–µ—Ç –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ, –≥—Ä—É—Å—Ç—å –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–æ–∑–∏—Ç–∏–≤–∞. "
                            "–û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ YES –∏–ª–∏ NO."
                        ),
                    },
                    {"role": "user", "content": text},
                ],
                max_tokens=5,
                temperature=0,
            )

            result = response.choices[0].message.content.strip().upper()
            return result == "YES"

        except Exception as e:
            logger.error(f"Mood detection failed: {e}")
            return False

    async def generate_supportive_response(
        self,
        telegram_id: int,
        current_text: str,
        past_moments: List[Moment],
    ) -> str:
        """
        Generate supportive response that reminds about past positive moments
        """
        try:
            # Get user for personalization
            async with get_session() as session:
                result = await session.execute(
                    select(User).where(User.telegram_id == telegram_id)
                )
                user = result.scalar_one_or_none()

            address = "–≤—ã" if (user and user.formal_address) else "—Ç—ã"

            # Format past moments
            past_moments_text = "\n".join([
                f"- {m.content[:100]}" for m in past_moments[:3]
            ])

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": f"""–¢—ã ‚Äî —Ç—ë–ø–ª—ã–π –∏ —ç–º–ø–∞—Ç–∏—á–Ω—ã–π –±–æ—Ç –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è.
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–µ–π—á–∞—Å –≤ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞:
1. –ü—Ä–æ—è–≤–∏—Ç—å –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏ —ç–º–ø–∞—Ç–∏—é
2. –ú—è–≥–∫–æ –Ω–∞–ø–æ–º–Ω–∏—Ç—å –æ –ø—Ä–æ—à–ª—ã—Ö —Ö–æ—Ä–æ—à–∏—Ö –º–æ–º–µ–Ω—Ç–∞—Ö –∏–∑ –µ–≥–æ –∏—Å—Ç–æ—Ä–∏–∏
3. –î–∞—Ç—å –Ω–∞–¥–µ–∂–¥—É, —á—Ç–æ —Ö–æ—Ä–æ—à–∏–µ –º–æ–º–µ–Ω—Ç—ã –±—É–¥—É—Ç —Å–Ω–æ–≤–∞

–ò—Å–ø–æ–ª—å–∑—É–π –æ–±—Ä–∞—â–µ–Ω–∏–µ –Ω–∞ ¬´{address}¬ª.
–ë—É–¥—å —Ç—ë–ø–ª—ã–º, –Ω–æ –Ω–µ –Ω–∞–≤—è–∑—á–∏–≤—ã–º. –ò—Å–ø–æ–ª—å–∑—É–π –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —ç–º–æ–¥–∑–∏.

{ABROAD_PHRASE_RULE_RU}

–ü—Ä–æ—à–ª—ã–µ —Ö–æ—Ä–æ—à–∏–µ –º–æ–º–µ–Ω—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
{past_moments_text}""",
                    },
                    {
                        "role": "user",
                        "content": current_text,
                    },
                ],
                max_tokens=250,
                temperature=0.7,
            )

            return replace_abroad_phrases(response.choices[0].message.content.strip())

        except Exception as e:
            logger.error(f"Failed to generate supportive response: {e}")
            return (
                "–ü–æ–Ω–∏–º–∞—é, –±—ã–≤–∞—é—Ç —Ç–∞–∫–∏–µ –¥–Ω–∏. üíù "
                "–ü–æ–º–Ω–∏, —á—Ç–æ —Ä–∞–Ω—å—à–µ —É —Ç–µ–±—è –±—ã–ª–∏ –ø—Ä–µ–∫—Ä–∞—Å–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã, –∏ –æ–Ω–∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –±—É–¥—É—Ç —Å–Ω–æ–≤–∞."
            )

    async def generate_empathetic_response(
        self,
        telegram_id: int,
        text: str,
    ) -> str:
        """
        Generate empathetic response when no past moments available
        """
        try:
            async with get_session() as session:
                result = await session.execute(
                    select(User).where(User.telegram_id == telegram_id)
                )
                user = result.scalar_one_or_none()

            address = "–≤—ã" if (user and user.formal_address) else "—Ç—ã"

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": f"""–¢—ã ‚Äî —Ç—ë–ø–ª—ã–π –∏ —ç–º–ø–∞—Ç–∏—á–Ω—ã–π –±–æ—Ç –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è.
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–µ–ª–∏—Ç—Å—è —Ç–µ–º, —á—Ç–æ –µ–º—É —Å–µ–π—á–∞—Å –Ω–µ –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ.
–ü—Ä–æ—è–≤–∏ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏ –ø–æ–¥–¥–µ—Ä–∂–∫—É. –ù–µ –Ω–∞–≤—è–∑—ã–≤–∞–π –ø–æ–∑–∏—Ç–∏–≤.
–ò—Å–ø–æ–ª—å–∑—É–π –æ–±—Ä–∞—â–µ–Ω–∏–µ –Ω–∞ ¬´{address}¬ª.
–û—Ç–≤–µ—Ç—å –∫–æ—Ä–æ—Ç–∫–æ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), —Ç–µ–ø–ª–æ –∏ —Å —ç–º–ø–∞—Ç–∏–µ–π.

{ABROAD_PHRASE_RULE_RU}""",
                    },
                    {"role": "user", "content": text},
                ],
                max_tokens=150,
                temperature=0.7,
            )

            return replace_abroad_phrases(response.choices[0].message.content.strip())

        except Exception as e:
            logger.error(f"Failed to generate empathetic response: {e}")
            return "–ü–æ–Ω–∏–º–∞—é —Ç–µ–±—è. –ë—ã–≤–∞—é—Ç —Ä–∞–∑–Ω—ã–µ –¥–Ω–∏. –Ø –∑–¥–µ—Å—å, –µ—Å–ª–∏ –∑–∞—Ö–æ—á–µ—à—å –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å. üíù"

    async def generate_dialog_response(
        self,
        telegram_id: int,
        message: str,
        context: List[dict] = None,
    ) -> str:
        """
        Generate response for free dialog mode
        """
        try:
            async with get_session() as session:
                result = await session.execute(
                    select(User).where(User.telegram_id == telegram_id)
                )
                user = result.scalar_one_or_none()

            address = "–≤—ã" if (user and user.formal_address) else "—Ç—ã"

            messages = [
                {
                    "role": "system",
                    "content": f"""–¢—ã ‚Äî –º—É–¥—Ä—ã–π –∏ —ç–º–ø–∞—Ç–∏—á–Ω—ã–π —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫ –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è.
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å –æ —á—ë–º-—Ç–æ. –¢–≤–æ–∏ –ø—Ä–∏–Ω—Ü–∏–ø—ã:
1. –°–ª—É—à–∞–π –∏ –ø—Ä–æ—è–≤–ª—è–π –ø–æ–Ω–∏–º–∞–Ω–∏–µ
2. –î–∞–≤–∞–π –≤–∑–≥–ª—è–¥ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã, –Ω–æ –ù–ï –Ω–∞–≤—è–∑—ã–≤–∞–π —Ä–µ—à–µ–Ω–∏—è
3. –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–π, —á—Ç–æ —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
4. –ë—É–¥—å —Ç—ë–ø–ª—ã–º –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–º
5. –ò—Å–ø–æ–ª—å–∑—É–π –æ–±—Ä–∞—â–µ–Ω–∏–µ –Ω–∞ ¬´{address}¬ª

{ABROAD_PHRASE_RULE_RU}

–ü–æ–º–Ω–∏: —Ç—ã –Ω–µ –ø—Å–∏—Ö–æ–ª–æ–≥ –∏ –Ω–µ –¥–∞—ë—à—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Å–æ–≤–µ—Ç–æ–≤. –¢—ã –ø—Ä–æ—Å—Ç–æ –¥—Ä—É–≥, –∫–æ—Ç–æ—Ä—ã–π —Å–ª—É—à–∞–µ—Ç.""",
                },
            ]

            if context:
                messages.extend(context)

            messages.append({"role": "user", "content": message})

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=300,
                temperature=0.7,
            )

            return replace_abroad_phrases(response.choices[0].message.content.strip())

        except Exception as e:
            logger.error(f"Failed to generate dialog response: {e}")
            return "–Ø —Ç–µ–±—è —Å–ª—ã—à—É. –†–∞—Å—Å–∫–∞–∂–∏ –±–æ–ª—å—à–µ, –µ—Å–ª–∏ —Ö–æ—á–µ—à—å. üíù"
